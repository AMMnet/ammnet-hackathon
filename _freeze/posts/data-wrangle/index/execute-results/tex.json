{
  "hash": "40dfbe3464c51ac1be553d99c6e6642c",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Data Wrangling in R\"\nformat: beamer\nauthor:   \n  - Justin Millar \n  - Ellie Sherrard-Smith\n  - Christian Selinger\n  - Lazaro Mwandigha\ndate: \"2024-10-14\"\ncategories: \n - R\n - Data cleaning\n - Data validation\n---\n\n\n## Introduction\n\n### What do we mean with data wrangling?\n\nThe Cambridge dictionary gives several meanings to the verb [wrangle](https://dictionary.cambridge.org/dictionary/english/wrangle):\n\n1. to argue with someone about something, especially for a long time\n\n2. to take care of, control, or move animals, especially large animals such as cows or horses (*mainly American English*)\n\n3. to move a person or thing somewhere, usually with difficulty or using force \n\n4. to take care of or **deal with something, usually when this is difficult**\n\n\n### Data Wrangling\n\nBy data wrangling, we mean here the process of checking and correcting quality and \nintegrity of data relevant to malaria modeling, prior to any further analysis. \nThis is also known as data validation.\n\n**Data validation** involves checking various aspects of your dataset, such as missing values, \ndata types, outliers, and adherence to specific rules or constraints. \n\nValidating our data helps maintain its **quality and integrity**, ensuring that any \nanalyses or decisions made based on the data are robust and reliable.\n\n\n### Why Validate Data?\n\nEnsure Data **Integrity**: Validating data helps identify and rectify errors, ensuring the integrity of the dataset.\n\nImprove Analysis **Accuracy**: Clean and validated data leads to more accurate analysis and modeling results.\n\nCompliance and **Standards**: Data validation ensures that the data conforms to predefined rules, standards, or regulatory requirements.\n\nError **Prevention**: Early detection of errors can prevent downstream issues and save time in troubleshooting.\n\n\n## Getting Started\n\nBefore you begin, you might want to create a new project in RStudio. This can be done by clicking on the \"New Project\" button in the upper right corner of the RStudio window. You can then name the project and choose a directory to save it in.\n\nNext, we will load the `tidyverse` package. This package provides a set of useful functions for data manipulation and visualization. We will use the `ggplot2` package to create plots in the later section of this tutorial.\n\n\n\n::: {.cell}\n\n:::\n\n\nNext, let's download the two example datasets we will use in this tutorial. These are available in the [AMMnet Hackathon GitHub repository](https://github.com/AMMnet/AMMnet-Hackathon). \n\nI suggest creating a `data` folder inside your R project, then we can download the two example datasets so that they are saved to your computer.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\nThe two datasets we will use are `mockdata_cases1.csv` and `mosq_mock1.csv`, which are mock example datasets that should be similar to malaria case surveillance and mosquito field collection data, respectively. In the following sections we will use the `mockdata_cases1.csv` and `mosq_mock1.csv` to introduce concepts of data cleaning and characterization in R. \n\n## 1.  Check the data for potential errors\n\n### Prevalence is a fraction defined in [0,1]\n\n**Note:** Prevalence of 0 or 1 while not statistically erroneous, need checking for accuracy.\n\nWhat observations have errors?\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 10\n  location month  year ages  total positive xcoord ycoord    prev time_order_loc\n  <chr>    <dbl> <dbl> <chr> <dbl>    <dbl>  <dbl>  <dbl>   <dbl>          <dbl>\n1 mordor       4  2018 15_a~    91       23  -20.0   30.5 25.3                 4\n2 neverwh~     2  2019 15_a~    22       -1  -20.8   29.6 -0.0455             14\n3 neverwh~     3  2018 unde~    25        0  -19.8   30.2  0                   3\n```\n:::\n:::\n\n**Comment:** We have two rows with nonsensical `prev` data `25.3`and `-0.455`, and one row with zero `prev` at a given month. \n\n\n### Defensive programming\n\n**Note:** The use of \"::\" enables us to call a function from a specific R package\n       I have had instances where if \"stats\" base R package was called first, \n       the filter function if not specified with the R package fails.\n\n::: {.cell}\n\n:::\n\n\n### We correct the two prevalence by re-calculating \n\nGood practice to leave the original data intact (advantage of R over Stata)\n\n\n::: {.cell}\n\n:::\n\nWe have a case erroneously reported with a negative value.\n\nWhat are your options?\n\n1. Never delete data\n\n2. Query and have data management team make the necessary investigations and make a correction\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 11\n  location month  year ages  total positive xcoord ycoord    prev time_order_loc\n  <chr>    <dbl> <dbl> <chr> <dbl>    <dbl>  <dbl>  <dbl>   <dbl>          <dbl>\n1 neverwh~     2  2019 15_a~    22       -1  -20.8   29.6 -0.0455             14\n2 neverwh~     3  2018 unde~    25        0  -19.8   30.2  0                   3\n# i 1 more variable: prev_updated <dbl>\n```\n:::\n:::\n\n\nFor now (in order to proceed with this demo), we drop the problematic observation.\n\nWhy is this not working?\n\n::: {.cell}\n\n:::\n\nWhy is this working?\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 11\n  location   month  year ages  total positive xcoord ycoord  prev time_order_loc\n  <chr>      <dbl> <dbl> <chr> <dbl>    <dbl>  <dbl>  <dbl> <dbl>          <dbl>\n1 neverwhere     3  2018 unde~    25        0  -19.8   30.2     0              3\n# i 1 more variable: prev_updated <dbl>\n```\n:::\n:::\n\n\n### Schemas\n\nTo prevent nonsensical data appearing in your data, you should define\na **schema** that comes along with your recorded data. A schema is a document that \nstates rules for data types and values or ranges to be expected in a particular \ncolumn of your data frame. \n\nE.g. for prevalence, we know that this should be a real number between \nzero and one.\n\nThe R package `validate` can be used to create a schema for your data frame:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n  name items passes fails nNA error warning             expression\n1   V1   514    513     1   0 FALSE   FALSE     prev - 0 >= -1e-08\n2   V2   514    513     1   0 FALSE   FALSE      prev - 1 <= 1e-08\n3   V3   514    513     1   0 FALSE   FALSE positive - 0 >= -1e-08\n```\n:::\n:::\n\nUsing the schema for the columns `prev` and `positive`, we could have readily detected \nthe three problematic entries. For more details, you can have a look into the\n[vignette](https://cran.r-project.org/web/packages/validate/vignettes/cookbook.html) \nof the `validate` package.\n\n**Note:** Next time when you receive data from your collaborators, you might want to\nask them for the associated schema file (e.g. YAML format). Good luck!\n\n## 2.  Look at summary statistics\n### Summary stats by location (across all time points)\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 5\n  location    nobs mean_prev min_prev max_prev\n  <chr>      <int>     <dbl>    <dbl>    <dbl>\n1 mordor       105     0.314   0.158     0.488\n2 narnia       104     0.326   0.08      0.488\n3 neverwhere    95     0.301   0         0.486\n4 oz           104     0.255   0.0714    0.459\n5 wonderland   105     0.382   0.194     0.535\n```\n:::\n:::\n\n\n### Summary stats by location and year (across all time points)\n\nTable getting longer. Might be too cumbersome to add checks by month and age group\nNote: point of query - why just had 3 measurements in 2020? \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 6\n# Groups:   location [5]\n   location    year  nobs mean_prev min_prev max_prev\n   <chr>      <dbl> <int>     <dbl>    <dbl>    <dbl>\n 1 mordor      2018    36     0.318   0.206     0.473\n 2 mordor      2019    36     0.313   0.170     0.451\n 3 mordor      2020    33     0.312   0.158     0.488\n 4 narnia      2018    36     0.340   0.138     0.449\n 5 narnia      2019    36     0.361   0.216     0.488\n 6 narnia      2020    32     0.270   0.08      0.483\n 7 neverwhere  2018    36     0.304   0         0.45 \n 8 neverwhere  2019    56     0.298   0.0370    0.486\n 9 neverwhere  2020     3     0.307   0.04      0.473\n10 oz          2018    35     0.252   0.0714    0.459\n11 oz          2019    36     0.254   0.0861    0.446\n12 oz          2020    33     0.260   0.112     0.405\n13 wonderland  2018    36     0.365   0.255     0.454\n14 wonderland  2019    36     0.388   0.194     0.535\n15 wonderland  2020    33     0.393   0.276     0.476\n```\n:::\n:::\n\n\n::: {#challenge1 .callout-tip}\n## Challenge 1: Explore the `data_prev` and `data_use` datasets\n* Create a table showing the number of data entries per age group and location for each of them!\n* Which age group and location have observations removed?\n:::\n\n\nSlightly more advanced. Use of lists (not scope of the course but there is a point here).\n\n::: {.cell}\n\n:::\n\nOr use the `purrr` library:\n\n::: {.cell}\n\n:::\n\n\n### Now let's focus on the first list object (mordor)                         \nWe know pregnant mothers, children <5 are most vulnerable.\n\nOutput (ages) isn't ordered as we would want (chronologically).\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 7\n# Groups:   location, year [3]\n  location  year ages      nobs mean_prev min_prev max_prev\n  <chr>    <dbl> <chr>    <int>     <dbl>    <dbl>    <dbl>\n1 mordor    2018 15_above    12     0.270    0.206    0.369\n2 mordor    2018 5_to_14     12     0.335    0.219    0.427\n3 mordor    2018 under_5     12     0.348    0.259    0.473\n4 mordor    2019 15_above    12     0.266    0.170    0.377\n5 mordor    2019 5_to_14     12     0.278    0.176    0.390\n6 mordor    2019 under_5     12     0.394    0.315    0.451\n7 mordor    2020 15_above    11     0.255    0.158    0.333\n8 mordor    2020 5_to_14     11     0.352    0.258    0.488\n9 mordor    2020 under_5     11     0.330    0.190    0.422\n```\n:::\n:::\n\n\n### How to proceed?\n\n\n::: {.cell}\n\n:::\n\nLet's compare the two\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 7\n# Groups:   location, year [3]\n  location  year ages      nobs mean_prev min_prev max_prev\n  <chr>    <dbl> <chr>    <int>     <dbl>    <dbl>    <dbl>\n1 mordor    2018 15_above    12     0.270    0.206    0.369\n2 mordor    2018 5_to_14     12     0.335    0.219    0.427\n3 mordor    2018 under_5     12     0.348    0.259    0.473\n4 mordor    2019 15_above    12     0.266    0.170    0.377\n5 mordor    2019 5_to_14     12     0.278    0.176    0.390\n6 mordor    2019 under_5     12     0.394    0.315    0.451\n7 mordor    2020 15_above    11     0.255    0.158    0.333\n8 mordor    2020 5_to_14     11     0.352    0.258    0.488\n9 mordor    2020 under_5     11     0.330    0.190    0.422\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 7\n# Groups:   location, year [3]\n  location  year age_group  nobs mean_prev min_prev max_prev\n  <chr>    <dbl> <fct>     <int>     <dbl>    <dbl>    <dbl>\n1 mordor    2018 under_5      12     0.348    0.259    0.473\n2 mordor    2018 5_to_14      12     0.335    0.219    0.427\n3 mordor    2018 15_above     12     0.270    0.206    0.369\n4 mordor    2019 under_5      12     0.394    0.315    0.451\n5 mordor    2019 5_to_14      12     0.278    0.176    0.390\n6 mordor    2019 15_above     12     0.266    0.170    0.377\n7 mordor    2020 under_5      11     0.330    0.190    0.422\n8 mordor    2020 5_to_14      11     0.352    0.258    0.488\n9 mordor    2020 15_above     11     0.255    0.158    0.333\n```\n:::\n:::\n\n\n\n\n## 3.  Use of graphs\n### We need to assess the evolution of prevalence for all regions by month\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-evoplot-1.pdf)\n:::\n:::\n\n\n**Observation:** Prevalence graph with vertical lines per month and year, means we have several subgroups for prevalence data, we plot facets for levels of `age_group`\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-evoplot-fix1-1.pdf)\n:::\n:::\n\n**Observation**: \nSome improvements, but we still have vertical lines, maybe we have other group variables. Let's only look at those rows that have more than one entry per location, month, year, age_group\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 48 x 13\n# Groups:   location, month, year [8]\n   location   month  year age_group     n ages     total positive xcoord ycoord\n   <chr>      <dbl> <dbl> <fct>     <int> <chr>    <dbl>    <dbl>  <dbl>  <dbl>\n 1 neverwhere     6  2019 under_5       2 under_5     24        4  -20.6   30.7\n 2 neverwhere     6  2019 under_5       2 under_5     26        1  -20.5   30.7\n 3 neverwhere     6  2019 5_to_14       2 5_to_14     27        5  -19.7   30.0\n 4 neverwhere     6  2019 5_to_14       2 5_to_14     27        8  -19.3   30.2\n 5 neverwhere     6  2019 15_above      2 15_above    70       31  -19.4   29.4\n 6 neverwhere     6  2019 15_above      2 15_above    74       27  -19.2   29.2\n 7 neverwhere     7  2019 under_5       2 under_5     25        5  -20.0   29.1\n 8 neverwhere     7  2019 under_5       2 under_5     26        4  -20.7   28.6\n 9 neverwhere     7  2019 5_to_14       2 5_to_14     27        7  -18.8   29.3\n10 neverwhere     7  2019 5_to_14       2 5_to_14     23        6  -20.4   29.8\n# i 38 more rows\n# i 3 more variables: prev <dbl>, time_order_loc <dbl>, prev_updated <dbl>\n```\n:::\n:::\n\n**Observation:** \nOK, we see that within one location there are several prevalence data points, they differ by the `xcoord` and `ycoord`. In order to plot by location, we could average across `xcoord` and `ycoord` witin each location; maybe those are duplicated recordings, since `xcoord` and `ycoord` are very close?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-evoplot-fix3-1.pdf)\n:::\n:::\n\n**Observation:** \nPrevalence widely variable throughout they year across the locations on average, wonderland affected by high prevalence while oz has the lowest prevalence\n\n\n# Need to check (not just prevalence) but count of cases and total vulnerable\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-casecount-1.pdf)\n:::\n:::\n\n**Observation:** \nStacked bar graph adds positive and total counts, better to show  them side by side as positive counts are a subset of the total counts. This is a specified by the argument `position=\"dodge\"` in the `geom_bar` geometry of `ggplot2`.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-casecount-dodgedbar-1.pdf)\n:::\n:::\n\n\n## The mosquito data set\n\nLet's take a look at the `mosq_data`dataset.\n\nWe check the sanity of this data set by displaying a table of recorded values per column:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n$session\nx\n 1  2 \n52 52 \n\n$Village\nx\nnaernia  narnia \n      2     102 \n\n$Compound.ID\nx\n 1  2  3  4 \n26 26 26 26 \n\n$Method\nx\nALC HLC \n  1 103 \n\n$Location\nx\n Indoor Outdoor \n     52      52 \n\n$hour\nx\n01h-02h 02h-03h 03h-04h 04h-05h 05h-06h 06h-07h 07h-08h 19h-20h 20h-21h 21h-22h \n      8       8       8       8       8       8       8       8       8       8 \n22h-23h 23h-24h 24h-01h \n      8       8       8 \n\n$ag.Male\nx\n 0  3  4  5  6  7 14 16 20 22 27 35 \n93  1  1  1  1  1  1  1  1  1  1  1 \n\n$Ag.unfed\nx\n 0  1  2  3  4  5  6  7  8 10 20 \n57 13  7  8  4  4  2  4  2  1  2 \n\n$Ag.halffed\nx\n 0  3  4  5  8  9 \n92  3  3  3  1  2 \n\n$Ag.fed\nx\n 0  1  3  5 \n88  7  3  6 \n\n$Ag.grsgr\nx\n 0  1  2  3  4  6  8 12 17 20 23 27 35 37 \n70 13  6  1  2  1  3  2  1  1  1  1  1  1 \n\n$tot.gamb\nx\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 23 \n40 10 10  9  8  6  3  2  1  1  5  2  1  2  2  2 \n\n$Culex.male\nx\n  0 \n104 \n\n$Culex.female\nx\n 0  1  2 \n94  9  1 \n\n$Mansonia.male\nx\n  0   1 \n103   1 \n\n$Mansonia.female\nx\n 0  1  2 \n90 11  3 \n\n$Aedes.male\nx\n  0 \n104 \n\n$Aedes.female\nx\n 0  1  2 \n98  5  1 \n```\n:::\n:::\n\nLooks like we have some typos in the names for `Method` and `Village`.\n\n::: {#challenge2 .callout-tip}\n## Challenge 2: Using schemas for the mosquito data set\n\n* Create a *schema* that provides rules for the strings (i.e. words) to be expected \nin the columns `Method` and `Village`.\n* Use the syntax from [here](#data-validation-schema)\n:::\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n  name items passes fails nNA error warning                expression\n1   V1   104    103     1   0 FALSE   FALSE     Method %vin% c(\"HLC\")\n2   V2   104    102     2   0 FALSE   FALSE Village %vin% c(\"narnia\")\n```\n:::\n:::\n\n\n\n\nThe columns `Village` and `Method` seem to have some data entry errors. We need to correct for that.\n\n::: {.cell}\n\n:::\n\n\nIt looks like the several columns concern *Anopheles Gambiae* population sizes. Let's change the column names using `rename` from the `tidyverse` package.\n\n::: {.cell}\n\n:::\n\n\nSeems like the `tot.gamb` should count the the total number of Anopheles \nGambiae populations. Let's check:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 x 2\n   AnophelesGambiae_total tot.gamb\n                    <dbl>    <dbl>\n 1                     12        0\n 2                     16        2\n 3                      0        6\n 4                     24        8\n 5                     24        1\n 6                     74       12\n 7                     54        3\n 8                     70        1\n 9                     34        2\n10                     40        2\n11                     46        0\n```\n:::\n:::\n\nOK, so 11 out of 104 rows have this discrepancy. Let's keep rather `Anopheles.total`,\nsince it was calculated from the data.\n\nSince the status of the Anopheles is mutually exclusive in the HLC data, we can draw\na stacked bar chart, with the bar color defined by the status. To produce such \na graph efficiently in `ggplot2`, we need to pivot the table.\n\nHere in particular we want to switch from a wide format to a long format  table \nin order to obtain a column describing the status of the Anopheles mosquitoes.\nWe will use in particular the `names_sep`argument of the `pivot_longer` function\nto separate e.g. the column name `AnophelesGambiae.male` and use `male`as level\nin a new column called `status`. The same goes for other column names. \n\nSetting the grouping variable to `session`, `Village`, `Compound.ID`, `Method`, \n`Location`, `hour`, `AnophelesGambiae_total` will help to keep those variables \nin the long format table.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-mosqdata-pivot-1.pdf)\n:::\n:::\n\n**Observation**: We had several values for `Compound.ID`. The `geom_bar` geometry\nis automatically adding them up in the graph. We can use `facet_wrap`to see those\nstrata:\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-mosqdata-pivot-line-1.pdf)\n:::\n:::\n\nOn we can also use our variable `Anopheles_total` and plot is as a line graph on top\nof the bar graph:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-beamer/data-mosqdata-pivot-disagg-1.pdf)\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}